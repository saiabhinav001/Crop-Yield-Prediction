{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb16774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544cd4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process weather files...\n",
      "\n",
      "✅ All weather files have been processed and combined!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PART 1: PROCESS ALL 30 DISTRICT WEATHER FILES\n",
    "# ==============================================================================\n",
    "district_filenames = {\n",
    "    'ANUGUL':'data/anugul.csv',\n",
    "    'BALANGIR':'data/balangir.csv',\n",
    "    'BALESHWAR':'data/baleshwar.csv',\n",
    "    'BARGARH':'data/bargarh.csv',\n",
    "    'BHADRAK':'data/bhadrak.csv',\n",
    "    'BOUDH':'data/boudh.csv',\n",
    "    'CUTTACK':'data/cuttack.csv',\n",
    "    'DEOGARH':'data/deogarh.csv',\n",
    "    'DHENKANAL':'data/dhenkanal.csv',\n",
    "    'GAJAPATI':'data/gajapati.csv',\n",
    "    'GANJAM':'data/ganjam.csv',\n",
    "    'JAGATSINGHPUR':'data/jagatsinghpur.csv',\n",
    "    'JAJAPUR':'data/jajapur.csv',\n",
    "    'JHARSUGUDA':'data/jharsuguda.csv',\n",
    "    'KALAHANDI':'data/kalahandi.csv',\n",
    "    'KANDHAMAL':'data/kandhamal.csv',\n",
    "    'KENDRAPARA':'data/kendrapara.csv',\n",
    "    'KENDUJHAR':'data/kendujhar.csv',\n",
    "    'KHORDHA':'data/khordha.csv',\n",
    "    'KORAPUT':'data/koraput.csv',\n",
    "    'MALKANGIRI':'data/malkangiri.csv',\n",
    "    'MAYURBHANJ':'data/mayurbhanj.csv',\n",
    "    'NABARANGPUR':'data/nabarangpur.csv',\n",
    "    'NAYAGARH':'data/nayagarh.csv',\n",
    "    'NUAPADA':'data/nuapada.csv',\n",
    "    'PURI': 'data/puri.csv',\n",
    "    'RAYAGADA':'data/rayagada.csv',\n",
    "    'SAMBALPUR':'data/sambalpur.csv',\n",
    "    'SONEPUR':'data/sonepur.csv',\n",
    "    'SUNDARGARH':'data/sundargarh.csv'\n",
    "}\n",
    "\n",
    "# An empty list to store the processed data for each district\n",
    "all_weather_data = []\n",
    "\n",
    "def get_season(month):\n",
    "    if 6 <= month <= 10: return 'Kharif'\n",
    "    elif month in [11, 12, 1, 2, 3]: return 'Rabi'\n",
    "    else: return 'Summer'\n",
    "\n",
    "print(\"Starting to process weather files...\")\n",
    "for district_name, file_name in district_filenames.items():\n",
    "    try:\n",
    "        temp_df = pd.read_csv(file_name, skiprows=13)\n",
    "        temp_df['DATE'] = pd.to_datetime(temp_df['YEAR'].astype(str) + temp_df['DOY'].astype(str), format='%Y%j')\n",
    "        temp_df['Month'] = temp_df['DATE'].dt.month\n",
    "        temp_df['Season'] = temp_df['Month'].apply(get_season)\n",
    "        seasonal_data = temp_df.groupby(['YEAR', 'Season']).agg(avg_temp=('T2M', 'mean'),max_temp=('T2M_MAX', 'max'),min_temp=('T2M_MIN', 'min'),total_rainfall=('PRECTOTCORR', 'sum')).reset_index()\n",
    "        seasonal_data.rename(columns={'YEAR': 'Year'}, inplace=True)\n",
    "        seasonal_data['District_Name'] = district_name\n",
    "        all_weather_data.append(seasonal_data)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ❌ ERROR: File not found for {district_name}: '{file_name}'.\")\n",
    "final_weather_df = pd.concat(all_weather_data, ignore_index=True)\n",
    "print(\"\\n✅ All weather files have been processed and combined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6314a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and cleaning the main crop production data (APY.csv)...\n",
      "✅ Crop data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PART 2: LOAD AND PREPARE CROP DATA\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nLoading and cleaning the main crop production data (APY.csv)...\")\n",
    "df_crop = pd.read_csv('data/APY.csv')\n",
    "df_crop.columns = df_crop.columns.str.strip()\n",
    "df_odisha = df_crop[df_crop['State'] == 'Odisha'].copy()\n",
    "df_odisha.rename(columns={'Crop_Year': 'Year', 'District': 'District_Name'}, inplace=True)\n",
    "print(\"✅ Crop data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bee5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUGGING: CHECKING KEYS BEFORE MERGE ---\n",
      "\n",
      "1. Unique districts in Crop Data:\n",
      "['ANUGUL', 'BALANGIR', 'BALESHWAR', 'BARGARH', 'BHADRAK', 'BOUDH', 'CUTTACK', 'DEOGARH', 'DHENKANAL', 'GAJAPATI', 'GANJAM', 'JAGATSINGHAPUR', 'JAJAPUR', 'JHARSUGUDA', 'KALAHANDI', 'KANDHAMAL', 'KENDRAPARA', 'KENDUJHAR', 'KHORDHA', 'KORAPUT', 'MALKANGIRI', 'MAYURBHANJ', 'NABARANGPUR', 'NAYAGARH', 'NUAPADA', 'PURI', 'RAYAGADA', 'SAMBALPUR', 'SONEPUR', 'SUNDARGARH']\n",
      "\n",
      "2. Unique districts in Weather Data:\n",
      "['ANUGUL', 'BALANGIR', 'BALESHWAR', 'BARGARH', 'BHADRAK', 'BOUDH', 'CUTTACK', 'DEOGARH', 'DHENKANAL', 'GAJAPATI', 'GANJAM', 'JAGATSINGHPUR', 'JAJAPUR', 'JHARSUGUDA', 'KALAHANDI', 'KANDHAMAL', 'KENDRAPARA', 'KENDUJHAR', 'KHORDHA', 'KORAPUT', 'MALKANGIRI', 'MAYURBHANJ', 'NABARANGPUR', 'NAYAGARH', 'NUAPADA', 'PURI', 'RAYAGADA', 'SAMBALPUR', 'SONEPUR', 'SUNDARGARH']\n",
      "\n",
      "3. Unique seasons in Crop Data (after cleaning spaces):\n",
      "['Autumn' 'Summer' 'Winter' 'Kharif' 'Rabi' 'Whole Year']\n",
      "\n",
      "4. Unique seasons in Weather Data:\n",
      "['Kharif' 'Rabi' 'Summer']\n",
      "\n",
      "--- END DEBUGGING ---\n",
      "\n",
      "✅ Merge complete!\n",
      "\n",
      "--- MASTER DATASET READY FOR MODEL TRAINING ---\n",
      "    State District_Name_x       Crop  Year     Season_x    Area  Production  \\\n",
      "1  Odisha          ANUGUL  Arhar/Tur  1997  Summer        469.0       115.0   \n",
      "3  Odisha          ANUGUL  Arhar/Tur  1999  Kharif       7960.0      5010.0   \n",
      "4  Odisha          ANUGUL  Arhar/Tur  2000  Kharif       8930.0      6430.0   \n",
      "5  Odisha          ANUGUL  Arhar/Tur  2002  Kharif       8730.0      6050.0   \n",
      "6  Odisha          ANUGUL  Arhar/Tur  2003  Kharif       9500.0      6500.0   \n",
      "\n",
      "   Yield Season_y   avg_temp  max_temp  min_temp  total_rainfall  \\\n",
      "1   0.25   Summer  31.696393     45.56     18.99          135.95   \n",
      "3   0.63   Kharif  26.761830     41.06     16.73         1217.58   \n",
      "4   0.72   Kharif  26.927124     37.95     15.42          856.98   \n",
      "5   0.69   Kharif  27.205163     41.70     15.52         1014.24   \n",
      "6   0.68   Kharif  27.460915     46.23     18.55         1639.26   \n",
      "\n",
      "  District_Name_y  \n",
      "1          ANUGUL  \n",
      "3          ANUGUL  \n",
      "4          ANUGUL  \n",
      "5          ANUGUL  \n",
      "6          ANUGUL  \n",
      "\n",
      "Your final dataset has 7227 rows.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PART 3: DEBUG AND MERGE\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- DEBUGGING: CHECKING KEYS BEFORE MERGE ---\")\n",
    "\n",
    "# Standardize the keys\n",
    "df_odisha['Season_Clean'] = df_odisha['Season'].str.strip()\n",
    "df_odisha['District_Name_Clean'] = df_odisha['District_Name'].str.upper()\n",
    "\n",
    "# Print the unique values from both DataFrames\n",
    "print(\"\\n1. Unique districts in Crop Data:\")\n",
    "print(sorted(df_odisha['District_Name_Clean'].unique()))\n",
    "\n",
    "print(\"\\n2. Unique districts in Weather Data:\")\n",
    "print(sorted(final_weather_df['District_Name'].unique()))\n",
    "\n",
    "print(\"\\n3. Unique seasons in Crop Data (after cleaning spaces):\")\n",
    "print(df_odisha['Season_Clean'].unique())\n",
    "\n",
    "print(\"\\n4. Unique seasons in Weather Data:\")\n",
    "print(final_weather_df['Season'].unique())\n",
    "\n",
    "print(\"\\n--- END DEBUGGING ---\")\n",
    "\n",
    "\n",
    "# Perform the merge using the CLEANED columns\n",
    "master_df = pd.merge(df_odisha, final_weather_df,\n",
    "                     left_on=['District_Name_Clean', 'Year', 'Season_Clean'],\n",
    "                     right_on=['District_Name', 'Year', 'Season'],\n",
    "                     how='left')\n",
    "\n",
    "# Drop helper columns\n",
    "master_df = master_df.drop(columns=['District_Name_Clean', 'Season_Clean'])\n",
    "\n",
    "master_df.dropna(subset=['avg_temp'], inplace=True)\n",
    "print(\"\\n✅ Merge complete!\")\n",
    "print(\"\\n--- MASTER DATASET READY FOR MODEL TRAINING ---\")\n",
    "print(master_df.head())\n",
    "print(f\"\\nYour final dataset has {len(master_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b247e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master DataFrame Info:\n",
      "Shape: (7227, 14)\n",
      "Columns: ['State', 'District_Name_x', 'Crop', 'Year', 'Season_x', 'Area', 'Production', 'Yield', 'Season_y', 'avg_temp', 'max_temp', 'min_temp', 'total_rainfall', 'District_Name_y']\n",
      "\n",
      "First few rows:\n",
      "    State District_Name_x       Crop  Year     Season_x    Area  Production  \\\n",
      "1  Odisha          ANUGUL  Arhar/Tur  1997  Summer        469.0       115.0   \n",
      "3  Odisha          ANUGUL  Arhar/Tur  1999  Kharif       7960.0      5010.0   \n",
      "4  Odisha          ANUGUL  Arhar/Tur  2000  Kharif       8930.0      6430.0   \n",
      "5  Odisha          ANUGUL  Arhar/Tur  2002  Kharif       8730.0      6050.0   \n",
      "6  Odisha          ANUGUL  Arhar/Tur  2003  Kharif       9500.0      6500.0   \n",
      "\n",
      "   Yield Season_y   avg_temp  max_temp  min_temp  total_rainfall  \\\n",
      "1   0.25   Summer  31.696393     45.56     18.99          135.95   \n",
      "3   0.63   Kharif  26.761830     41.06     16.73         1217.58   \n",
      "4   0.72   Kharif  26.927124     37.95     15.42          856.98   \n",
      "5   0.69   Kharif  27.205163     41.70     15.52         1014.24   \n",
      "6   0.68   Kharif  27.460915     46.23     18.55         1639.26   \n",
      "\n",
      "  District_Name_y  \n",
      "1          ANUGUL  \n",
      "3          ANUGUL  \n",
      "4          ANUGUL  \n",
      "5          ANUGUL  \n",
      "6          ANUGUL  \n",
      "\n",
      "Merged data exported to: merged_apy_data.csv\n",
      "File saved with 7227 rows and 14 columns.\n"
     ]
    }
   ],
   "source": [
    "# Check the merged data and export to CSV\n",
    "print(\"Master DataFrame Info:\")\n",
    "print(f\"Shape: {master_df.shape}\")\n",
    "print(f\"Columns: {list(master_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(master_df.head())\n",
    "\n",
    "# Export the merged data to CSV\n",
    "output_file = \"merged_apy_data.csv\"\n",
    "master_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nMerged data exported to: {output_file}\")\n",
    "print(f\"File saved with {len(master_df)} rows and {len(master_df.columns)} columns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
